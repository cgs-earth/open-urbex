{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# urbex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noqa\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from whitebox.whitebox_tools import WhiteboxTools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import leafmap.leafmap as lm\n",
    "import rasterio\n",
    "import sys\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "# Add parent directory to path\n",
    "\n",
    "module_path = str(Path(os.getcwd()).parents[1])\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "os.chdir(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noqa\n",
    "\n",
    "from IO.Scripts.Modules.utilities import create_dd_con, move_pathlib  # noqa\n",
    "from IO.Scripts.Modules.setup import (  # noqa\n",
    "    dwnld_import,\n",
    "    create_extents,\n",
    "    wgs84_to_utm,\n",
    "    folder_set_up,\n",
    "    test_set_up,\n",
    "    alt_poly,\n",
    ")\n",
    "from IO.Scripts.Modules.terrain import get_terrain_data  # noqa\n",
    "from IO.Scripts.Modules.vectors import (  # noqa\n",
    "    ox_trans_load,\n",
    "    filt_load_bldgs,\n",
    "    water_dwnld_clean,\n",
    "    points_2_csv,\n",
    "    roads_dwnld_filt,\n",
    "    places_dwnld,\n",
    "    big_roads_only,\n",
    ")\n",
    "from IO.Scripts.Modules.rasters import (  # noqa\n",
    "    run_kde,\n",
    "    kde_to_city_center,\n",
    "    export_kde_raster,\n",
    "    vec_2_rast,\n",
    "    distance_accumulation,\n",
    "    node_dist_grid,\n",
    "    array_2_tif,\n",
    "    background_points,\n",
    "    stack_rasters,\n",
    "    samples_with_data,\n",
    "    tif_2_ascii,\n",
    "    raster_out,\n",
    ")\n",
    "from IO.Scripts.Modules.netx import node2cc  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro (Always Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "cityid = 597\n",
    "out_path = Path(r\"C:\\Users\\MAtkinson\\Documents\\GitHub\\urbex\\IO\\Data\")\n",
    "maxent = r\"C:\\Users\\MAtkinson\\Documents\\GitHub\\urbex\\IO\\maxent\\maxent.jar\"\n",
    "release = \"2025-12-17.0\"\n",
    "overture_location = \"s3://overturemaps-us-west-2\"\n",
    "alt = {\n",
    "    \"fp\": out_path / r\"Rwanda/Kigali/Google/wb_KK_polygons/Kigali_Kamonyi.shp\",\n",
    "    \"id\": \"597000\",\n",
    "    \"city\": \"Kigali\",\n",
    "    \"country\": \"Rwanda\",\n",
    "}  # or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download city shape, name, and country\n",
    "if isinstance(alt, dict):\n",
    "    uc = alt_poly(fp=alt[\"fp\"], id=alt[\"id\"], city=alt[\"city\"], country=alt[\"country\"])\n",
    "else:\n",
    "    uc = dwnld_import(cityid, out_path)\n",
    "\n",
    "# Create extent data and projected crs from city shape\n",
    "extentPoly, zoom, bounds, xmin, xmax, ymin, ymax = create_extents(uc.geometry)\n",
    "UTMZone, wkid = wgs84_to_utm(uc.geometry)\n",
    "\n",
    "# extract city and country name\n",
    "city_name = uc[\"GC_UCN_MAI_2025\"].tolist()[0]\n",
    "country_name = uc[\"GC_CNT_GAD_2025\"].tolist()[0]\n",
    "\n",
    "# set up folder structure\n",
    "outfp, fdict = folder_set_up(out_path, city_name, country_name)\n",
    "test_set_up()\n",
    "print(outfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOWNLOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "\n",
    "# connect to duckdb\n",
    "con = create_dd_con()\n",
    "\n",
    "# elevation\n",
    "get_terrain_data(bounds, zoom, fdict[\"Downloads\"], city_name)\n",
    "\n",
    "# transportation\n",
    "ox_trans_load(extentPoly, fdict[\"Downloads\"], city_name, delfile=False)\n",
    "\n",
    "# buildings\n",
    "filt_load_bldgs(\n",
    "    dloc=f\"{overture_location}/release/{release}/theme=buildings/type=building/*\",\n",
    "    big_out=None,\n",
    "    pt_out=None,\n",
    "    samp_out=str(fdict[\"Downloads\"] / f\"{city_name}_bldg_samp_pts.shp\"),\n",
    "    cols=\"subtype, class, height, num_floors, geometry\",\n",
    "    xmin=xmin,\n",
    "    xmax=xmax,\n",
    "    ymin=ymin,\n",
    "    ymax=ymax,\n",
    "    con=con,\n",
    ")\n",
    "\n",
    "# roads\n",
    "roads_dwnld_filt(\n",
    "    fdict,\n",
    "    city_name,\n",
    "    xmin,\n",
    "    xmax,\n",
    "    ymin,\n",
    "    ymax,\n",
    "    oloc=overture_location,\n",
    "    relnum=release,\n",
    "    con=con,\n",
    "    delfile=False,\n",
    ")\n",
    "\n",
    "# places\n",
    "places_dwnld(\n",
    "    fdict,\n",
    "    city_name,\n",
    "    xmin,\n",
    "    xmax,\n",
    "    ymin,\n",
    "    ymax,\n",
    "    oloc=overture_location,\n",
    "    relnum=release,\n",
    "    con=con,\n",
    "    delfile=False,\n",
    ")\n",
    "\n",
    "# water\n",
    "water_dwnld_clean(\n",
    "    city_name,\n",
    "    fdict[\"Intermediate\"],\n",
    "    xmin,\n",
    "    xmax,\n",
    "    ymin,\n",
    "    ymax,\n",
    "    wkid,\n",
    "    oloc=overture_location,\n",
    "    relnum=release,\n",
    "    con=con,\n",
    "    delfile=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREP FOR MAXENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Density  Estimation of City Centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "- https://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity\n",
    "- https://www.spatialanalysisonline.com/HTML/index.html?density__kernels_and_occupancy.htm\n",
    "- https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/how-kernel-density-works.htm\n",
    "- https://gistbok-topics.ucgis.org/AM-03-008\n",
    "- https://pygis.io/docs/e_summarize_vector.html#method-2-display-and-export-with-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plFPath = fdict[\"Downloads\"] / f\"{city_name}_plcs.shp\"\n",
    "places = gpd.read_file(plFPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_places, xct, yct = run_kde(places, xmin, ymin, xmax, ymax, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_pt = kde_to_city_center(\n",
    "    kde_places, xct, yct, city_name, country_name, xmin, xmax, ymin, ymax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "cc_pt.plot(ax=ax, markersize=1, color=\"yellow\")\n",
    "ax.imshow(np.rot90(kde_places), cmap=\"Reds\", extent=(xmin, xmax, ymin, ymax))\n",
    "uc.plot(ax=ax, color=\"none\", edgecolor=\"dimgray\")\n",
    "ax.set_title(\n",
    "    f\"{city_name}, {country_name} - Kernel Density Estimation for Places\",\n",
    "    fontdict={\"fontsize\": \"15\", \"fontweight\": \"3\"},\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export raster\n",
    "fp = fdict[\"Intermediate\"] / f\"{city_name}_plc_kde.tif\"\n",
    "export_kde_raster(kde_places, xct, yct, xmin, xmax, ymin, ymax, proj=4326, filename=fp)\n",
    "# Export City Center\n",
    "cc_pt.to_file(fdict[\"Intermediate\"] / f\"{city_name}_city_center.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Distance to City Center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    " - https://docs.momepy.org/en/stable/user_guide/graph/convert.html\n",
    " - https://gdal.org/en/stable/tutorials/gdal_grid_tut.html\n",
    " - https://github.com/nathanjmcdougall/geospatial-wheels-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in roads and city center\n",
    "rdFPath = fdict[\"Intermediate\"] / f\"{city_name}_con_rds.shp\"\n",
    "filt_rds = gpd.read_file(rdFPath)\n",
    "\n",
    "ccFPath = fdict[\"Intermediate\"] / f\"{city_name}_city_center.shp\"\n",
    "cc = gpd.read_file(ccFPath).to_crs(wkid)\n",
    "\n",
    "# get distance from nodes to city center\n",
    "nodes = node2cc(filt_rds, cc, wkid).to_crs(4326)\n",
    "nodes.to_file(fdict[\"Intermediate\"] / f\"{city_name}_nodes_dist.shp\")\n",
    "\n",
    "del filt_rds, cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn nodes with distance into grid w/ idw\n",
    "grid_z, grid_x, grid_y, xy_coords = node_dist_grid(nodes, xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distance grid\n",
    "plt.plot(xy_coords[:, 0], xy_coords[:, 1], \"k.\", ms=1)\n",
    "plt.imshow(grid_z.T, extent=(0, 1, 0, 1), origin=\"lower\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Cubic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn grid array to tiff file (export)\n",
    "idw_fp = array_2_tif(grid_z, grid_x, grid_y, fdict, city_name, xmin, xmax, ymin, ymax)\n",
    "\n",
    "del idw_fp, grid_z, grid_x, grid_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevationPath = f\"{city_name}_elevation.tif\"\n",
    "slopePath = f\"{city_name}_slope.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if first time it will download the extension\n",
    "# even if already in uv environment\n",
    "wbt = WhiteboxTools()\n",
    "wbt.set_working_dir(fdict[\"Downloads\"])\n",
    "wbt.slope(elevationPath, slopePath, None, units=\"degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fp in [elevationPath, slopePath]:\n",
    "    if not Path(fdict[\"Model_Inputs\"] / fp).exists():\n",
    "        move_pathlib(\n",
    "            src_path=(fdict[\"Downloads\"] / fp), dest_path=(fdict[\"Model_Inputs\"] / fp)\n",
    "        )\n",
    "    else:\n",
    "        print(\"Please delete file first before replacing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopeTIF = fdict[\"Model_Inputs\"] / f\"{city_name}_slope.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance accumulation from roads\n",
    "roadPath = fdict[\"Downloads\"] / f\"{city_name}_rds.shp\"\n",
    "roadTIF = fdict[\"Intermediate\"] / f\"{city_name}_rds.tif\"\n",
    "roaddistTIF = fdict[\"Model_Inputs\"] / f\"{city_name}_rd_dist.tif\"\n",
    "\n",
    "filtRdPath = big_roads_only(roadPath, fdict, city_name)\n",
    "vec_2_rast(filtRdPath, slopeTIF, roadTIF)\n",
    "distance_accumulation(roadTIF, roaddistTIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance accumulation from water\n",
    "waterPath = fdict[\"Intermediate\"] / f\"{city_name}_all_water.shp\"\n",
    "waterTIF = fdict[\"Intermediate\"] / f\"{city_name}_all_water.tif\"\n",
    "waterdistTIF = fdict[\"Model_Inputs\"] / f\"{city_name}_all_water_dist.tif\"\n",
    "\n",
    "vec_2_rast(waterPath, slopeTIF, waterTIF)\n",
    "distance_accumulation(waterTIF, waterdistTIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance accumulation from transit\n",
    "transPath = fdict[\"Downloads\"] / f\"{city_name}_trans.shp\"\n",
    "transTIF = fdict[\"Intermediate\"] / f\"{city_name}_trans.tif\"\n",
    "transdistTIF = fdict[\"Model_Inputs\"] / f\"{city_name}_trans_dist.tif\"\n",
    "\n",
    "vec_2_rast(transPath, slopeTIF, transTIF)\n",
    "distance_accumulation(transTIF, transdistTIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE MAXENT INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raster Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    f\"{city_name}_elevation\": \"elevation\",\n",
    "    f\"{city_name}_all_water_dist\": \"wt_dist\",\n",
    "    f\"{city_name}_nodes2cc_dist_idw_coreg\": \"cc_dist\",\n",
    "    f\"{city_name}_rd_dist\": \"rd_dist\",\n",
    "    f\"{city_name}_slope\": \"slope\",\n",
    "    f\"{city_name}_trans_dist\": \"tr_dist\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tif to ascii\n",
    "for f in Path(fdict[\"Model_Inputs\"]).glob(\"*.tif\"):\n",
    "    new_stem = rename_dict[f.stem]\n",
    "    tif_2_ascii(f, fdict[\"Model_Inputs_ASCII\"] / f\"{new_stem}.asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdict = {\n",
    "    \"elevation\": fdict[\"Model_Inputs\"] / f\"{city_name}_elevation.tif\",\n",
    "    \"wt_dist\": fdict[\"Model_Inputs\"] / f\"{city_name}_all_water_dist.tif\",\n",
    "    \"cc_dist\": fdict[\"Model_Inputs\"] / f\"{city_name}_nodes2cc_dist_idw_coreg.tif\",\n",
    "    \"rd_dist\": fdict[\"Model_Inputs\"] / f\"{city_name}_rd_dist.tif\",\n",
    "    \"slope\": fdict[\"Model_Inputs\"] / f\"{city_name}_slope.tif\",\n",
    "    \"tr_dist\": fdict[\"Model_Inputs\"] / f\"{city_name}_trans_dist.tif\",\n",
    "}\n",
    "rout = fdict[\"Downloads\"] / f\"{city_name}_rstack.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnames = stack_rasters(rdict, rout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_raster = fdict[\"Model_Inputs\"] / f\"{city_name}_elevation.tif\"\n",
    "bp_shp = fdict[\"Intermediate\"] / f\"{city_name}_background_points.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bps = background_points(\n",
    "    sample_raster,\n",
    "    bp_shp,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Samples With Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = fdict[\"Downloads\"] / f\"{city_name}_bldg_samp_pts.shp\"\n",
    "s_swd_shp = fdict[\"Presence_Data\"] / f\"{city_name}_bldg_samp_swd.shp\"\n",
    "s_swd_csv = fdict[\"Presence_Data\"] / f\"{city_name}_bldg_samp_swd.csv\"\n",
    "b_swd_shp = fdict[\"Presence_Data\"] / f\"{city_name}_background_swd.shp\"\n",
    "b_swd_csv = fdict[\"Presence_Data\"] / f\"{city_name}_background_swd.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_with_data(samples=samp, lnames=rnames, rstack_fp=rout, s_out_fp=s_swd_shp)\n",
    "samples_with_data(samples=bp_shp, lnames=rnames, rstack_fp=rout, s_out_fp=b_swd_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_2_csv(s_swd_shp, s_swd_csv, swd=True, layers=rnames, delfile=True)\n",
    "points_2_csv(b_swd_shp, b_swd_csv, swd=True, layers=rnames, delfile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAXENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raster Inputs to MAXENT:\n",
    "- Distance to City Center\n",
    "- Distance from Roads\n",
    "- Distance from Water\n",
    "- Distance from Transit\n",
    "- Slope\n",
    "- Elevation\n",
    "\n",
    "#### Sources:\n",
    "- [GitHub Repo for MAXENT](https://github.com/mrmaxent/Maxent)\n",
    "- [Download & Documentation Page for MAXENT](https://biodiversityinformatics.amnh.org/open_source/maxent/)\n",
    "\n",
    "Instructions:\n",
    "Download MAXENT zip from AMNH and unzip it into folder named \"MAXENT\" in the IO folder. Make sure you have the \"maxent.jar\" file. Also make sure you have Java downloaded on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run MAXENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call(\n",
    "    [\n",
    "        \"java\",\n",
    "        \"-jar\",\n",
    "        str(maxent),\n",
    "        f\"environmentallayers={b_swd_csv}\",\n",
    "        f\"projectionlayers={fdict['Model_Inputs_ASCII'] }\",\n",
    "        f\"samplesfile={s_swd_csv}\",\n",
    "        f\"outputdirectory={fdict['Model_Outputs']}\",\n",
    "        \"redoifexists\",\n",
    "        \"autorun\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj = (\n",
    "    'GEOGCS[\"GCS_WGS_1984\",'\n",
    "    'DATUM[\"D_WGS_1984\",'\n",
    "    'SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],'\n",
    "    'PRIMEM[\"Greenwich\",0.0],'\n",
    "    'UNIT[\"Degree\",0.0174532925199433]'\n",
    "    \"]\"\n",
    ")\n",
    "for x in fdict[\"Model_Outputs\"].glob(\"*.asc\"):\n",
    "    with open(\n",
    "        Path(fdict[\"Model_Outputs\"], f\"{x.stem}.prj\"), \"w\", encoding=\"utf-8\"\n",
    "    ) as q:\n",
    "        q.write(prj)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert ASCII to TIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascfp = fdict[\"Model_Outputs\"] / \"Building_Model_Inputs_ASCII.asc\"\n",
    "exfp = fdict[\"Model_Inputs\"] / f\"{city_name}_elevation.tif\"\n",
    "outfp = fdict[\"Model_Outputs\"] / \"Building_Model_Inputs_ASCII.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_out(rast=rasterio.open(ascfp).read(1), ofp=outfp, exfp=exfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISPLAY MAXENT OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = lm.Map(center=(extentPoly.centroid.y, extentPoly.centroid.x), zoom=12)\n",
    "m.add_basemap(\"Esri.WorldImagery\")\n",
    "m.add_raster(\n",
    "    str(outfp), colormap=mpl.colormaps[\"turbo\"], layer_name=\"urbex output\"\n",
    ")  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
